{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GhIt9y90t0jq",
    "outputId": "e9e27a70-78a2-46a6-ce34-f5934b3edefc"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import folium\n",
    "from IPython.display import display\n",
    "\n",
    "# API Key removed\n",
    "# API_KEY = \"\"\n",
    "\n",
    "# Create map centered on Austin\n",
    "m = folium.Map(location=[30.2672, -97.7431], zoom_start=12)\n",
    "m.add_child(folium.LatLngPopup())\n",
    "\n",
    "display(m)\n",
    "print(\"Click on the map to get coordinates, then use them below:\")\n",
    "\n",
    "# Get location from user\n",
    "lat = float(input(\"Enter latitude: \"))\n",
    "lng = float(input(\"Enter longitude: \"))\n",
    "\n",
    "# Categories to search\n",
    "categories = [\n",
    "    'grocery_or_supermarket',\n",
    "    'pharmacy',\n",
    "    'hospital',\n",
    "    'doctor',\n",
    "    'dentist',\n",
    "    'veterinary_care',\n",
    "    'restaurant',\n",
    "    'cafe',\n",
    "    'bar',\n",
    "    'gym',\n",
    "    'park',\n",
    "    'spa',\n",
    "    'shopping_mall',\n",
    "    'convenience_store',\n",
    "    'transit_station',\n",
    "    'bus_station',\n",
    "    'subway_station',\n",
    "    'gas_station',\n",
    "    'movie_theater',\n",
    "    'museum',\n",
    "    'library',\n",
    "    'night_club',\n",
    "    'school',\n",
    "    'university',\n",
    "    'bank',\n",
    "    'atm',\n",
    "    'post_office',\n",
    "    'laundry',\n",
    "    'police',\n",
    "    'fire_station'\n",
    "]\n",
    "\n",
    "# Calculate 4 points in a square pattern around center\n",
    "offset_miles = 5.0\n",
    "lat_offset = offset_miles / 69.0\n",
    "lng_offset = offset_miles / 54.6\n",
    "\n",
    "search_points = [\n",
    "    (lat + lat_offset, lng + lng_offset),  # Northeast\n",
    "    (lat + lat_offset, lng - lng_offset),  # Northwest\n",
    "    (lat - lat_offset, lng + lng_offset),  # Southeast\n",
    "    (lat - lat_offset, lng - lng_offset),  # Southwest\n",
    "]\n",
    "\n",
    "url = \"https://maps.googleapis.com/maps/api/place/nearbysearch/json\"\n",
    "all_results = {}\n",
    "\n",
    "print(f\"\\nSearching {len(categories)} categories across 4 locations...\")\n",
    "print(\"This may take a minute...\\n\")\n",
    "\n",
    "for category in categories:\n",
    "    category_count = 0\n",
    "    for search_lat, search_lng in search_points:\n",
    "        params = {\n",
    "            \"location\": f\"{search_lat},{search_lng}\",\n",
    "            \"radius\": 8000,  # 5 miles per search point\n",
    "            \"type\": category,\n",
    "            \"key\": API_KEY\n",
    "        }\n",
    "\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "\n",
    "        if data['status'] == 'OK':\n",
    "            for place in data['results']:\n",
    "                place_id = place['place_id']\n",
    "                if place_id not in all_results:\n",
    "                    all_results[place_id] = place\n",
    "                    category_count += 1\n",
    "\n",
    "    print(f\"âœ“ {category}: {category_count} new places found\")\n",
    "\n",
    "# Convert back to list\n",
    "data = {'results': list(all_results.values())}\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total unique places found: {len(data['results'])}\")\n",
    "print(f\"{'='*60}\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gObwGd7-uQoB",
    "outputId": "ad65da2f-11fa-4e26-b6ae-433d76361145"
   },
   "outputs": [],
   "source": [
    "for place in data['results']:\n",
    "    name = place['name']\n",
    "    rating = place.get('rating', 'N/A')\n",
    "\n",
    "    # Get coordinates\n",
    "    lat = place['geometry']['location']['lat']\n",
    "    lng = place['geometry']['location']['lng']\n",
    "\n",
    "    # Get categories/types (Google returns a list of types)\n",
    "    categories = ', '.join(place.get('types', []))\n",
    "\n",
    "    print(f\"{name}\")\n",
    "    print(f\"  Rating: {rating}\")\n",
    "    print(f\"  Coordinates: ({lat}, {lng})\")\n",
    "    print(f\"  Categories: {categories}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "2hrtp47GzQn8",
    "outputId": "f9ede610-13de-4877-c1bd-016436ebb894"
   },
   "outputs": [],
   "source": [
    "# This cell does the grouping for neighborhood level average sentiment with the reddit posts attatched.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "apt_df = pd.read_csv('/content/apartments_with_neighborhood.csv')\n",
    "reddit_df = pd.read_csv('/content/reddit_posts_with_neighborhoods (1).csv')\n",
    "\n",
    "reddit_df.head()\n",
    "rgrouped = reddit_df.groupby('neighborhood_assigned')['sentiment_score'].mean().reset_index()\n",
    "rgrouped.head()\n",
    "\n",
    "reddit_df = pd.merge(reddit_df, rgrouped, on='neighborhood_assigned', how='left')\n",
    "reddit_df = reddit_df.rename(columns={'sentiment_score_y': 'Average_Sentiment'})\n",
    "reddit_df.head()\n",
    "\n",
    "# Join apartment data with neighborhood sentiment scores\n",
    "apt_df = pd.merge(\n",
    "    apt_df,\n",
    "    rgrouped,\n",
    "    left_on='neighborhood_group',\n",
    "    right_on='neighborhood_assigned',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Rename the sentiment column to be clearer\n",
    "apt_df = apt_df.rename(columns={'sentiment_score': 'sentiment_score'})\n",
    "\n",
    "# Drop the duplicate neighborhood column if you don't need it\n",
    "apt_df = apt_df.drop(columns=['neighborhood_assigned'], errors='ignore')\n",
    "\n",
    "# Normalize sentiment scores to 0-100 scale\n",
    "# Assuming sentiment_score is between -1 and 1 (adjust if different)\n",
    "if 'sentiment_score' in apt_df.columns:\n",
    "    apt_df['sentiment_score'] = ((apt_df['sentiment_score'] + 1) / 2) * 100\n",
    "    apt_df['sentiment_score'] = apt_df['sentiment_score'].fillna(50)  # Fill missing with neutral\n",
    "\n",
    "print(f\"Apartments with sentiment scores: {apt_df['sentiment_score'].notna().sum()}/{len(apt_df)}\")\n",
    "apt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mTCF7TNv5odh",
    "outputId": "79ff331f-b456-493f-cdaa-bee343e1b312"
   },
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import time\n",
    "\n",
    "# Initialize geocoder\n",
    "geolocator = Nominatim(user_agent=\"apartment_geocoder\")\n",
    "\n",
    "def geocode_address(address):\n",
    "    \"\"\"Geocode an address and return coordinates as a tuple\"\"\"\n",
    "    try:\n",
    "        location = geolocator.geocode(address, timeout=10)\n",
    "        if location:\n",
    "            return (location.latitude, location.longitude)\n",
    "        else:\n",
    "            return None\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        print(f\"Error geocoding {address}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error for {address}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Apply geocoding to the dataframe\n",
    "# Add a small delay to respect rate limits (Nominatim requires 1 second between requests)\n",
    "coords_list = []\n",
    "for idx, address in enumerate(apt_df['address']):\n",
    "    print(f\"Geocoding {idx+1}/{len(apt_df)}: {address}\")\n",
    "    coords = geocode_address(address)\n",
    "    coords_list.append(coords)\n",
    "    time.sleep(1)  # Required for Nominatim - 1 request per second\n",
    "\n",
    "apt_df['coords'] = coords_list\n",
    "\n",
    "# Optional: Split into separate lat/lon columns\n",
    "apt_df['latitude'] = apt_df['coords'].apply(lambda x: x[0] if x else None)\n",
    "apt_df['longitude'] = apt_df['coords'].apply(lambda x: x[1] if x else None)\n",
    "\n",
    "print(apt_df[['address', 'coords', 'latitude', 'longitude']].head())\n",
    "\n",
    "\n",
    "# Remove records where the address couldnt fill in\n",
    "\n",
    "apt_df = apt_df.dropna(subset=['latitude', 'longitude'])\n",
    "apt_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KEL_xp3I8QEF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WRlLGOpY-bDa",
    "outputId": "95fce9dc-efb5-4dac-a13d-185ec13e6926"
   },
   "outputs": [],
   "source": [
    "# Filter for distance to apartment\n",
    "# 5 Mile threshold\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance in miles between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    miles = 3956 * c  # Radius of earth in miles\n",
    "    return miles\n",
    "\n",
    "# Create new dataframe with only nearby apartments\n",
    "nearby_apartments = apt_df.copy()\n",
    "\n",
    "# Calculate distance for each apartment\n",
    "nearby_apartments['distance_miles'] = nearby_apartments.apply(\n",
    "    lambda row: haversine(row['longitude'], row['latitude'], lng, lat)\n",
    "    if pd.notna(row['latitude']) and pd.notna(row['longitude'])\n",
    "    else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Filter to only apartments within 5 miles\n",
    "nearby_apartments = nearby_apartments[nearby_apartments['distance_miles'] <= 5.0]\n",
    "\n",
    "# Sort by distance\n",
    "nearby_apartments = nearby_apartments.sort_values('distance_miles').reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nFound {len(nearby_apartments)} apartments within 5 miles\")\n",
    "print(nearby_apartments[['address', 'distance_miles']])\n",
    "\n",
    "# Original apt_df is unchanged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nW5hOd8icf6J"
   },
   "source": [
    "Claude Categories:\n",
    "Essential Services:\n",
    "\n",
    "grocery_or_supermarket - Grocery stores\n",
    "pharmacy - Pharmacies\n",
    "hospital - Hospitals/Emergency care\n",
    "doctor - Medical clinics\n",
    "dentist - Dental offices\n",
    "veterinary_care - Vet clinics (if you have pets)\n",
    "\n",
    "Food & Social:\n",
    "\n",
    "restaurant - Restaurants\n",
    "cafe - Coffee shops\n",
    "bar - Bars/Pubs\n",
    "\n",
    "Fitness & Wellness:\n",
    "\n",
    "gym - Gyms/Fitness centers\n",
    "park - Parks & green spaces\n",
    "spa - Spas/Wellness centers\n",
    "\n",
    "Shopping:\n",
    "\n",
    "shopping_mall - Shopping centers\n",
    "grocery_or_supermarket - (already listed above)\n",
    "convenience_store - Quick shopping\n",
    "\n",
    "Transportation:\n",
    "\n",
    "transit_station - Public transit stops\n",
    "bus_station - Bus stops\n",
    "subway_station - Metro/Subway\n",
    "gas_station - Gas stations\n",
    "\n",
    "Entertainment & Culture:\n",
    "\n",
    "movie_theater - Cinemas\n",
    "museum - Museums\n",
    "library - Libraries\n",
    "night_club - Nightlife\n",
    "\n",
    "Education (if relevant):\n",
    "\n",
    "school - Schools\n",
    "university - Colleges/Universities\n",
    "\n",
    "Convenience:\n",
    "\n",
    "bank - Banks\n",
    "atm - ATMs\n",
    "post_office - Post offices\n",
    "laundry - Laundromats\n",
    "\n",
    "Safety:\n",
    "\n",
    "police - Police stations\n",
    "fire_station - Fire stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "955aac867055425bbf0e6e48124da828",
      "c5e5f5ffcee74ea0bbd83b111289b08b",
      "d640419f04214f939636d8a1fdd50a5e",
      "a09ac2f7082844c7bff3ce6ecdc647ea",
      "28bd6f00a2c04dc090cdc13ee7cdcff2",
      "1cac0b1b401c4f3fabc294d0262990ee",
      "75f721ce3e574f2689bc12a50ad5ef0d",
      "6e790bd3194b46e0ac4c1450c3375f2e",
      "2d16f96c856d4a1fb0a2d11a73b5fee5",
      "0c8294f08ee74869976bfdace9bb9f52",
      "1d7217b6a45c48db9bd813520b90ba34",
      "83733fbfb1ed404999c1feac00cdb1f1",
      "42d8f50f2f76427d9d0fe95f90af175b",
      "c9b9450590db401a885cd1749abb9b96",
      "bcd70955c97040209b2dfd6f344d6398",
      "88cbe47a4e924a239b09964f5ccfa464",
      "c4931a70680c4395a56fd547bedec702",
      "74b64814f6e34f379baad3b4d70f4ec2",
      "d35aec812bcd43e586b2c166648d38d7",
      "f2b9d36fc5464766a88d67919ccbeb6a",
      "e3e7d3c6f5394cbb83fa4220ed81c697",
      "b71d9f9c3f594c018beb48080be8da06",
      "22381c3f44614b799e8dd833a3442f57",
      "627aa7fd7f2f4c7bb2eaa3f3e49cd95d",
      "44957aee50cd488298411adf946f3958",
      "8399b053e4d64a45977ee3259b2a4451",
      "d54c34ad793343e783b0c7d50a8397f9",
      "b155a29181424d2183abd4cfb9efea64",
      "8345dc51059340b5a16cbf86c4d9036a",
      "3914f59fe8e74a679964d9bd3c6fc0a8",
      "394c7388fc364a9b88961ec5daa25607",
      "ddb2d70d8c854423bce32c040a085c6b",
      "eb94ce313628496c8b360e2e1cfe5773",
      "39d8f039285642558b6af8c21ebf1bb5",
      "b3b6b299f27541c4be89d6b8b60efd83",
      "b3812f377d974d9b826749c48229871c",
      "e18883941ee749248e231a877b0cce92",
      "bcf4defccd6341819d448c02d3843450",
      "69959af2fbed4c6c827506b3987d378b",
      "8fda30de623f4a159d1cd3200cff2f85",
      "27d177a90d0b491a9780df285f31f988",
      "1a67205aed3b42c0bbcd92a721afe1c3",
      "e9dbbe904ba94192b9af6e0d908ac43f",
      "3e4a258f919843fd904b21a24aebcb23",
      "d1966c2770cf4cdaaa3b1ee0dc479391",
      "92248799600d42d3b1934b8e98fcd7df",
      "4045d7bced0441a2b43293f17662fbff",
      "19bb6d721e7b4c339118fdd9f9d0b4cb",
      "a0a87de60c31435285cf0dd48ad1f335",
      "18fa52e280e140ec8f6d7402edac621f",
      "b8b7e1b655e448f489b8aeccf7848f9b",
      "cd93a12e1bee43a6877a273baf845f53",
      "ec676a014bd34459a4e9f35cc580bd08",
      "212178c6ca6b48fc87014d91538a9d2b",
      "5c25013396e3483bb822a92430601a18",
      "1ebfe9d460764b47b7be79f1c428e417",
      "c88e0a91efe941d7a5904d8be507ede2",
      "aff2a303fef14de08f677e776a29e22f",
      "c2b9aa6211404f2a865163734ce37aed",
      "1fc7b2956eae462eb9e40f9f8d769a74",
      "42309e438e7a494485c053372ec15db2",
      "ac9c61e58aa044ccb83b661314a7c41c",
      "3415a67d1119470cb37725d0e3e3c45c",
      "8caaa2f9eb87463085cffde718ffa3cb",
      "ff3ee2c3dc4b4406ab766f25ebe4cbbc",
      "8496bd9fab684aa3a6e0988e130dfee2",
      "d36556b8be3d4442aa76435da31f8bd2",
      "507ef805bf7444198525bb65a01de74f",
      "a5deb58a871c4e8ab01288c7e2db237e",
      "3ab4359240ad4d4eb8e5c5037d36660c",
      "eb800e9f4ad64df6bae2e53314e8d13d",
      "dc9f918b840e43a098d203ef38ab54d4",
      "43e735afd08c4ab99eeaf0d4be876abc",
      "7ecc86f3574649058563ef3f76a94a2d",
      "55ae8a12a3fe4ac7bca0dcec0fcd8435",
      "0613d29ac9bf4f208211b296f9571ead",
      "d7e4faaab7d24e35abdcbf0888acfd47",
      "c43b64a0667d475da76d14e09a15c1e0",
      "4bb91449eebd4f82998854cb1386f77d",
      "d6b7e0e52cc249fda02188880f4c95a1",
      "bf28b3c3bbfa42278b682a59a72b8928",
      "8c5db639f5b24a57bd27fefe80d53b5f",
      "ea0144564aa345539378b788f1efc062",
      "ce11503929d843c39bb3cd20916dbacf",
      "aeddfd0bfddb40cdb7ce7f1786b6ea2a",
      "a8f9d22dc5134d9a8d43c794a919a234",
      "1caaeff83f0846a28858c32c7ea3cad0",
      "656767ffffa34e15bc49b5628c3f3bec",
      "065e6b7d12084aad9eb7636a347c3dbd",
      "781a7154927c4290adc22926917b2105",
      "43f9a09faad64fddb392cc4569be537e",
      "5e1773c03c294046ab3608eb34c2f22b",
      "836950abeaed4a589e75a9625877ee2b",
      "4902db3981ec46ec9e5852e3696f3d02",
      "b8973bf7781d47f49fa0ac12b582bc85",
      "6c4a0251f7bf47b49415d81794778a2f",
      "15556353bbc744f7815fad5d634904bf",
      "5de7b7e82e9742c395a1677ef93190e1",
      "cf0f2a8d883e432c9500b58457e67df1",
      "4725631dbf114f0b8dd7970fe379c31d",
      "70cecefca370415ea7ab410639010d1d",
      "41579a34032e44969a436355f2aa72a2",
      "c125058bc4cf4b0d8558418d6aed1fee",
      "8b76330a2a774a18b2747b2d0a8a5ea5",
      "03d28dfef6d64e188e3a8092a5827acd",
      "b74ae8287b52439aaaf369495b39ac9c",
      "d2fd4a801a3a488b9a5576f7710d33d7",
      "b023e6d9b9344345a39a9c44370182f9",
      "ae3dda3eb8ef4e099ed57d749a19d46f",
      "7748c957e2b54d20a134120a9758aea0",
      "b1cb545b3f1e432884f1c1e3cdc9a289",
      "a851a488b61a4bf6a90f5ad5227e5f01",
      "1f33c57256604541948882f0790df35e",
      "870e1419f1e24ff4bffe2f59088a5191",
      "dd588682aa2844c6a46e66ebd369b8a3",
      "4d9d3f28080c4e02b152b41c2db7dc16",
      "b20df1dfe0de4d7ab5d6a0f38774c401",
      "023020b929b0405896747dd8ead6f00d",
      "9a5d6828f39446e9949763c53d90521d",
      "286eb7ecbd2645e7ab671da18953cd56",
      "acb2f6ffbde94861bf3c707e3b00832a"
     ]
    },
    "id": "x-lKS4fDC8Uc",
    "outputId": "fc253b5d-e157-418c-86c4-b544079be063"
   },
   "outputs": [],
   "source": [
    "# scoring system.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Load a pretrained sentence transformer model for semantic similarity\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Google Places categories from your API call\n",
    "google_categories = [\n",
    "    'grocery_or_supermarket', 'pharmacy', 'hospital', 'doctor', 'dentist',\n",
    "    'veterinary_care', 'restaurant', 'cafe', 'bar', 'gym', 'park', 'spa',\n",
    "    'shopping_mall', 'convenience_store', 'transit_station', 'bus_station',\n",
    "    'subway_station', 'gas_station', 'movie_theater', 'museum', 'library',\n",
    "    'night_club', 'school', 'university', 'bank', 'atm', 'post_office',\n",
    "    'laundry', 'police', 'fire_station'\n",
    "]\n",
    "\n",
    "def match_user_input_to_categories(user_input, categories,\n",
    "                                   low_threshold=0.5,\n",
    "                                   high_threshold=0.7,\n",
    "                                   super_threshold=0.85):\n",
    "    \"\"\"\n",
    "    Match user input to Google Places categories using semantic similarity.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: (category, confidence_score, bonus_multiplier)\n",
    "    \"\"\"\n",
    "    # Encode user input and categories\n",
    "    user_embedding = model.encode([user_input])\n",
    "    category_embeddings = model.encode(categories)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarities = cosine_similarity(user_embedding, category_embeddings)[0]\n",
    "\n",
    "    # Filter and assign bonuses based on confidence\n",
    "    matches = []\n",
    "    for category, score in zip(categories, similarities):\n",
    "        if score < low_threshold:\n",
    "            continue  # Ignore low confidence\n",
    "        elif score >= super_threshold:\n",
    "            matches.append((category, score, 1.5))  # Super confident bonus\n",
    "        elif score >= high_threshold:\n",
    "            matches.append((category, score, 1.2))  # High confident bonus\n",
    "        else:\n",
    "            matches.append((category, score, 1.0))  # Regular match\n",
    "\n",
    "    return sorted(matches, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def calculate_amenity_score(apt_coords, places_data, user_input, matched_categories,\n",
    "                            max_distance_miles=5.0,\n",
    "                            category_weight=0.7,\n",
    "                            name_weight=0.3):\n",
    "    \"\"\"\n",
    "    Calculate amenity score based on proximity to matched places.\n",
    "    Uses BOTH category matching AND name similarity for better classification.\n",
    "\n",
    "    Args:\n",
    "        apt_coords: (lat, lng) tuple for apartment\n",
    "        places_data: dict with 'results' containing Google Places results\n",
    "        user_input: original user query (e.g., \"burger\", \"italian food\")\n",
    "        matched_categories: list of (category, confidence, bonus) tuples\n",
    "        max_distance_miles: maximum distance to consider\n",
    "        category_weight: how much category match matters (default 0.4)\n",
    "        name_weight: how much name match matters (default 0.6)\n",
    "\n",
    "    Returns:\n",
    "        float: amenity score (0-100)\n",
    "    \"\"\"\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "    def haversine(lon1, lat1, lon2, lat2):\n",
    "        lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "        c = 2 * asin(sqrt(a))\n",
    "        return 3956 * c  # miles\n",
    "\n",
    "    if not matched_categories:\n",
    "        return 0\n",
    "\n",
    "    apt_lat, apt_lng = apt_coords\n",
    "\n",
    "    # Encode user input once for name comparisons\n",
    "    user_embedding = model.encode([user_input])\n",
    "\n",
    "    # Get all matching places\n",
    "    matching_places = []\n",
    "    for place in places_data['results']:\n",
    "        place_types = place.get('types', [])\n",
    "        place_name = place.get('name', '')\n",
    "\n",
    "        # Check if place matches any of our categories\n",
    "        category_match = None\n",
    "        for category, confidence, bonus in matched_categories:\n",
    "            if category in place_types:\n",
    "                category_match = (confidence, bonus)\n",
    "                break\n",
    "\n",
    "        if category_match:\n",
    "            # Calculate name similarity\n",
    "            name_embedding = model.encode([place_name])\n",
    "            name_similarity = cosine_similarity(user_embedding, name_embedding)[0][0]\n",
    "\n",
    "            # Combined confidence score:\n",
    "            # Mix category confidence and name similarity\n",
    "            category_confidence, category_bonus = category_match\n",
    "            combined_confidence = (\n",
    "                category_confidence * category_weight +\n",
    "                name_similarity * name_weight\n",
    "            )\n",
    "\n",
    "            # Bonus multiplier: higher if both name and category match well\n",
    "            if name_similarity > 0.7 and category_confidence > 0.7:\n",
    "                final_bonus = category_bonus * 1.5  # Both match really well\n",
    "            elif name_similarity > 0.5:\n",
    "                final_bonus = category_bonus * 1.2  # Name matches decently\n",
    "            else:\n",
    "                final_bonus = category_bonus  # Just category match\n",
    "\n",
    "            place_lat = place['geometry']['location']['lat']\n",
    "            place_lng = place['geometry']['location']['lng']\n",
    "            distance = haversine(apt_lng, apt_lat, place_lng, place_lat)\n",
    "\n",
    "            if distance <= max_distance_miles:\n",
    "                matching_places.append({\n",
    "                    'name': place_name,\n",
    "                    'distance': distance,\n",
    "                    'combined_confidence': combined_confidence,\n",
    "                    'name_similarity': name_similarity,\n",
    "                    'category_confidence': category_confidence,\n",
    "                    'bonus': final_bonus\n",
    "                })\n",
    "\n",
    "    if not matching_places:\n",
    "        return 0\n",
    "\n",
    "    # Sort by combined score (confidence * distance proximity)\n",
    "    for place in matching_places:\n",
    "        distance_score = (max_distance_miles - place['distance']) / max_distance_miles * 100\n",
    "        place['weighted_score'] = distance_score * place['bonus'] * place['combined_confidence']\n",
    "\n",
    "    matching_places.sort(key=lambda x: x['weighted_score'], reverse=True)\n",
    "    top_places = matching_places[:3]\n",
    "\n",
    "    # Calculate final score\n",
    "    total_score = 0\n",
    "    for place in top_places:\n",
    "        total_score += place['weighted_score']\n",
    "\n",
    "    # Average and normalize\n",
    "    amenity_score = total_score / len(top_places)\n",
    "    return min(amenity_score, 100)  # Cap at 100\n",
    "\n",
    "\n",
    "def calculate_final_apartment_score(apt_row, places_data, user_amenities,\n",
    "                                    sentiment_weight=0.4,\n",
    "                                    distance_weight=0.3,\n",
    "                                    amenity_weight=0.3,\n",
    "                                    max_distance_miles=5.0):\n",
    "    \"\"\"\n",
    "    Calculate final apartment score combining sentiment, distance, and amenities.\n",
    "\n",
    "    Args:\n",
    "        apt_row: DataFrame row with apartment data\n",
    "        places_data: Google Places API results\n",
    "        user_amenities: list of amenities user cares about (e.g., ['elementary schools', 'parks'])\n",
    "        sentiment_weight: weight for sentiment score\n",
    "        distance_weight: weight for distance score\n",
    "        amenity_weight: weight for amenities score\n",
    "        max_distance_miles: max distance for scoring\n",
    "\n",
    "    Returns:\n",
    "        dict with breakdown of scores\n",
    "    \"\"\"\n",
    "    # 1. Sentiment score (assume already 0-100)\n",
    "    sentiment_score = apt_row.get('sentiment_score', 50)  # default to 50 if missing\n",
    "\n",
    "    # 2. Distance score\n",
    "    distance = apt_row['distance_miles']\n",
    "    distance_score = (max_distance_miles - distance) / max_distance_miles * 100\n",
    "\n",
    "    # 3. Amenity scores\n",
    "    apt_coords = apt_row['coords']\n",
    "    amenity_scores = []\n",
    "\n",
    "    for amenity in user_amenities:\n",
    "        # Match user amenity to Google categories\n",
    "        matches = match_user_input_to_categories(amenity, google_categories)\n",
    "\n",
    "        if matches:\n",
    "            # Calculate score for this amenity (now includes user_input for name matching)\n",
    "            score = calculate_amenity_score(apt_coords, places_data, amenity, matches, max_distance_miles)\n",
    "            amenity_scores.append(score)\n",
    "\n",
    "    # Average amenity scores\n",
    "    avg_amenity_score = np.mean(amenity_scores) if amenity_scores else 0\n",
    "\n",
    "    # 4. Calculate weighted final score\n",
    "    final_score = (\n",
    "        sentiment_score * sentiment_weight +\n",
    "        distance_score * distance_weight +\n",
    "        avg_amenity_score * amenity_weight\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        'final_score': final_score,\n",
    "        'sentiment_score': sentiment_score,\n",
    "        'distance_score': distance_score,\n",
    "        'amenity_score': avg_amenity_score,\n",
    "        'individual_amenity_scores': amenity_scores\n",
    "    }\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "# User inputs what they care about\n",
    "user_amenities = ['College', 'Thrift Shop', 'Nightclub']\n",
    "\n",
    "# Score all apartments\n",
    "scored_apartments = []\n",
    "for idx, apt in nearby_apartments.iterrows():\n",
    "    scores = calculate_final_apartment_score(\n",
    "        apt,\n",
    "        data,  # Google Places data from your API call\n",
    "        user_amenities,\n",
    "        sentiment_weight=0.4,\n",
    "        distance_weight=0.3,\n",
    "        amenity_weight=0.3\n",
    "    )\n",
    "\n",
    "    scored_apartments.append({\n",
    "        'address': apt['address'],\n",
    "        **scores\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "results_df = pd.DataFrame(scored_apartments)\n",
    "results_df = results_df.sort_values('final_score', ascending=False)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yl2Xopj7eZnM",
    "outputId": "66a4a302-fce8-49e2-dd08-36a70ea9b2b2"
   },
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "\n",
    "# User inputs what they care about\n",
    "user_amenities = ['Elementary School', 'pediatrician', 'Grocery Store']\n",
    "\n",
    "# Score all apartments\n",
    "scored_apartments = []\n",
    "for idx, apt in nearby_apartments.iterrows():\n",
    "    scores = calculate_final_apartment_score(\n",
    "        apt,\n",
    "        data,  # Google Places data from your API call\n",
    "        user_amenities,\n",
    "        sentiment_weight=0.4,\n",
    "        distance_weight=0.3,\n",
    "        amenity_weight=0.3\n",
    "    )\n",
    "\n",
    "    scored_apartments.append({\n",
    "        'address': apt['address'],\n",
    "        **scores\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "results_df = pd.DataFrame(scored_apartments)\n",
    "results_df = results_df.sort_values('final_score', ascending=False)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G_Y1FJh3c78Y",
    "outputId": "8ad04b63-9a48-4ffc-b403-a5ef61a4d0f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "\n",
    "# User inputs what they care about\n",
    "user_amenities = ['College', 'Thrift Shop', 'Nightclub']\n",
    "\n",
    "# Score all apartments\n",
    "scored_apartments = []\n",
    "for idx, apt in nearby_apartments.iterrows():\n",
    "    scores = calculate_final_apartment_score(\n",
    "        apt,\n",
    "        data,  # Google Places data from your API call\n",
    "        user_amenities,\n",
    "        sentiment_weight=0.4,\n",
    "        distance_weight=0.3,\n",
    "        amenity_weight=0.3\n",
    "    )\n",
    "\n",
    "    scored_apartments.append({\n",
    "        'address': apt['address'],\n",
    "        **scores\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame and sort\n",
    "college_results_df = pd.DataFrame(scored_apartments)\n",
    "college_results_df = college_results_df.sort_values('final_score', ascending=False)\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8v6KN7DceYAm",
    "outputId": "91e6eb71-ad4b-49fa-becc-899c267ff668"
   },
   "outputs": [],
   "source": [
    "college_results_df.to_csv('college_results.csv', index=False)\n",
    "results_df.to_csv('results.csv', index=False)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 554
    },
    "id": "gY_ZQSx3i1lQ",
    "outputId": "8585f823-32d8-4978-d480-ef5a083a453f"
   },
   "outputs": [],
   "source": [
    "reddit_df.groupby('neighborhood_assigned')['Average_Sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Flm2YMoktQY-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
